{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector machines (SVMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id='toc-container'><script type='text/javascript'>\n",
       "$(function() {\n",
       "    function regenTOC(){\n",
       "        element = $(\"#toc-container\");\n",
       "\n",
       "\tvar toc = document.createElement(\"div\");\n",
       "\t$(toc).attr(\"class\", \"table-of-contents\");\n",
       "\n",
       "\tvar curLevel = 0;\n",
       "\tvar containerStack = [toc];\n",
       "\tvar levelOfTag = {\"h2\": 1, \"h3\": 2, \"h4\": 3, \"h5\": 4};\n",
       "\n",
       "\tfunction pushLevel() {\n",
       "            var list = document.createElement(\"ul\");\n",
       "            containerStack.push(list);\n",
       "            curLevel++;\n",
       "\t}\n",
       "\t\n",
       "\tfunction popLevel() {\n",
       "            var lastContainer = containerStack.pop();\n",
       "            $(lastContainer).appendTo(containerStack[containerStack.length - 1]);\n",
       "            curLevel--;\n",
       "\t}\n",
       "\t\n",
       "\t$(\".text_cell_render :header\").each(function (i, elem) {\n",
       "            var level = levelOfTag[ elem.tagName.toLowerCase() ];\n",
       "\n",
       "            if (level === undefined)\n",
       "\t\treturn;\n",
       "\n",
       "            while (curLevel < level)\n",
       "\t\tpushLevel();\n",
       "            while (curLevel > level)\n",
       "\t\tpopLevel();\n",
       "            \n",
       "            var listItem = document.createElement(\"li\");\n",
       "            var link = document.createElement(\"a\");\n",
       "            $(link)\n",
       "\t\t.text($(elem).contents().first().text()) // Remove the pilcrow sign\n",
       "\t\t.attr(\"href\", \"#\" + $(elem).attr(\"id\"))\n",
       "\t\t.appendTo(listItem);\n",
       "            $(listItem).appendTo(containerStack[containerStack.length - 1]);\n",
       "\t});\n",
       "\t\n",
       "\twhile (curLevel > 0)\n",
       "            popLevel();\n",
       "\n",
       "        $(\"<a class='btn-update' href='#'>Update</a>\")\n",
       "          .click(regenTOC).prependTo(toc);\n",
       "\n",
       "\t$(toc).prepend(\"<div class='title'>Contents</div>\")\n",
       "          .wrap(\"<div class='toc-headings'/>\");\n",
       "\n",
       "        $(element).empty();\n",
       "        $(element).append(toc);\n",
       "    }\n",
       "\n",
       "    if (typeof(IPython) !== 'undefined')\n",
       "        $([IPython.events]).on('notebook_loaded.Notebook', regenTOC);\n",
       "    regenTOC();\n",
       "});\n",
       "\n",
       "</script></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import addutils.toc ; addutils.toc.js(ipy_notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".text_cell_render @font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    width: 900px;\n",
       "    margin-left: 0% !important;\n",
       "    margin-right: 0%;\n",
       "}\n",
       "\n",
       "code {\n",
       "    font-size:10pt;\n",
       "}\n",
       "\n",
       ".text_cell_render  h1 {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:28pt;\n",
       "}\n",
       ".text_cell_render h2 {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:24pt;\n",
       "}\n",
       ".text_cell_render h3 {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:20pt;\n",
       "}\n",
       ".text_cell_render h4 {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:18pt;\n",
       "    margin-top:12px;\n",
       "    margin-bottom: 3px;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {\n",
       "    font-weight: 300;\n",
       "    font-size: 11pt;\n",
       "    color: rgb( 48, 48, 48 );\n",
       "    font-style: italic;\n",
       "    margin-bottom: .5em;\n",
       "    margin-top: 0.5em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render ul {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 90, 90, 90 );\n",
       "    font-size:11pt;\n",
       "    line-height: 185%;\n",
       "}\n",
       "\n",
       ".text_cell_render yp {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 90, 90, 90 );\n",
       "    font-size:11pt;\n",
       "}\n",
       "\n",
       ".text_cell_render strong {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 30, 30, 30 );\n",
       "    font-size:11pt;\n",
       "}\n",
       "\n",
       ".text_cell_render a:link {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:11pt;\n",
       "}\n",
       "\n",
       ".text_cell_render a:visited {\n",
       "    color:rgb( 10, 88, 126 );\n",
       "}\n",
       "\n",
       ".text_cell_render {\n",
       "    font-family: Helvetica, Courier, Computer Modern, \"Helvetica Neue\", Arial, Geneva, sans-serif;\n",
       "    color: rgb( 84, 84, 84 );\n",
       "    font-size:11pt;\n",
       "    line-height: 125%;\n",
       "    font-size: 100%;\n",
       "    width:800px;\n",
       "}\n",
       "\n",
       ".CodeMirror {\n",
       "    font-family: Courier, \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "}\n",
       "\n",
       ".warning {\n",
       "    color: rgb( 240, 20, 20 );\n",
       "}\n",
       "\n",
       "/* Pandas tables */\n",
       "/*\n",
       ".rendered_html td {\n",
       "    text-align: right;\n",
       "}\n",
       "*/\n",
       "\n",
       "table.dataframe td {\n",
       "    text-align: right;\n",
       "}\n",
       "\n",
       ".output .table-of-contents {\n",
       "    border: 1px #cecece solid;\n",
       "    background-color: #fafafa;\n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 5px;\n",
       "    padding-right: 15px;\n",
       "    padding-left: 0px;\n",
       "    margin-bottom: 20px;\n",
       "    display: inline-block;\n",
       "    position: relative;\n",
       "}\n",
       "\n",
       ".output .table-of-contents ul {\n",
       "    list-style-type: none;\n",
       "    padding-left: 20px;\n",
       "}\n",
       "\n",
       ".output .table-of-contents .title {\n",
       "    font-weight: bold;\n",
       "    font-height: 11pt;\n",
       "    padding-left: 20px; /* looks better if it's the same to the <ul> */\n",
       "}\n",
       "\n",
       ".output .table-of-contents .btn-update {\n",
       "    position: absolute;\n",
       "    float: right;\n",
       "    right: 11px;\n",
       "    top: 4px;\n",
       "    font-size: 9pt;\n",
       "}\n",
       "\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from addutils import css_notebook\n",
    "css_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Support vector machines (SVMs)* is a supervised learning algorithm, primarily designed for classification that has been for a long period of time one of the most successful algorithm in ML. They are a good method because there is an intuition behind their formulation and the algorithm can be solved with optimization, and the solution can be interpreted intuitively.\n",
    "\n",
    "In the following section we will introduce the following notions:\n",
    "- Maximizing the margin\n",
    "- The solution\n",
    "- Kernel trick\n",
    "- Soft margin SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Better Linear Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that you have a dataset with linearly separable data. You could use several separating lines. If I look at the lines we can see their margin, we can ask ourselves, if I move the line a bit when is it too close than it can crossover (that is making an error)?\n",
    "\n",
    "*Which line (margin) is the best?*\n",
    "\n",
    "<img src=\"images/better_linear_separation.png\" alt=\"Better Linear Separation\" height=\"500\" width=\"500\"> \n",
    "\n",
    "It is tempting to say that bigger margin is better. Suppose you have a process that generates the data that has some noise. If the margin is bigger there could be more chance to correctly classify noisy data.\n",
    "\n",
    "Two question are worth answering:\n",
    "- Why bigger margin is better?\n",
    "- Which $w$ maximize the margin?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Bigger margin is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to classify a set of three points in the plane, using a line. A single line can separate all possible combinations of points?\n",
    "\n",
    "<img src=\"images/dichotomies.png\" alt=\"Dichotomies\" height=\"500\" width=\"500\"> \n",
    "\n",
    "Yes, it can. In a sense it has a low bias, all possible functions that can generate those three points can be learned. But this could be bad (remeber bias variance tradeoff?) and can lead to bad generalization.\n",
    "\n",
    "If we can restrict the line to be the ones that have fat margin? Can we increase the bias (decrease variance) and generalize better?\n",
    "\n",
    "<img src=\"images/dichotomies_fat.png\" alt=\"Dichotomies fat margin\" height=\"500\" width=\"500\">\n",
    "\n",
    "Suppose you can use only the lines that have a margin with at least a specific (fat) size to accept it. By putting a restriction on the dimension of the margin the model gets simpler (higher bias).\n",
    "\n",
    "(Actually this example refers to the theory of [**VC dimension**](https://en.wikipedia.org/wiki/VC_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Find the plane with bigger margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the distance from a point($x_0 ,y_0)$ to a line $Ax+By+c = 0$ is: \n",
    "\n",
    "$$\\frac{|A x_0 + B y_0 +c|}{\\sqrt{(A^2 +B^2)}}$$\n",
    "\n",
    "The distance between H and H1 is:\n",
    "\n",
    "$$\\frac{|w\\cdot x+b|}{||w||}=\\frac{1}{||w||}$$\n",
    "\n",
    "The distance between H1 and H2 is: \n",
    "\n",
    "$$\\frac{2}{||w||}$$\n",
    "\n",
    "In order to maximize the margin, we need to minimize $||w||$, with the condition that there are no datapoints between H1 and H2:\n",
    "\n",
    "$$\n",
    "x_i \\cdot w+b \\geq +1 \\rightarrow y_i =+1\\\\\n",
    "x_i \\cdot w+b \\leq -1 \\rightarrow y_i =-1\n",
    "$$\n",
    "\n",
    "Can be combined into \n",
    "\n",
    "$$y_i (x_i \\cdot w) \\geq 1$$\n",
    "\n",
    "The maximal margin touches some of the points, but it does not have points inside. The points that do not lie to either side of the margin are called interior points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/maximize_margin.png\"  alt=\"Margins\" height=\"500\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is: minimize $||w||$, such that discrimination boundary is obeyed, i.e., min f(x) s.t. g(x)=0, where:\n",
    "\n",
    "$$\n",
    "f: \\frac{1}{2} ||w||^2 \\\\\n",
    "g: y_i (x_i \\cdot w)+b = 1 \\quad or \\quad [y_i (x_i \\cdot w)+b] - 1 =0\n",
    "$$\n",
    "\n",
    "This is a constrained optimization problem that can be solved by Lagrangian multipler method and quadratic programming. We will not dig into the mathematical details of the solution because it will require a lot of time with many passages, please refer to [this](https://www.svm-tutorial.com/) if you want all the details. We will only sketch the solution because we will use it later on for the derivation of the kernel method and the soft margin version of SVM.\n",
    "\n",
    "This is the formulation of the lagrangian multiplier method:\n",
    "\n",
    "$$L ( x , \\alpha ) = f ( x ) + \\sum_i \\alpha_i g_i ( x )$$ \n",
    "\n",
    "$f(x)$ is the gradient max of $f$ and $g$ is the constraint condition. In our case, $f(x): \\frac{1}{2}||w||^2$ and $g(x): y_i (w\\cdot x_i +b)-1=0$ so the (primal) Lagrangian for SVM is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(w,b,\\alpha) \\equiv \\frac{1}{2}||w||^2 - \\sum_i \\alpha_i y_i (x_i \\cdot w + b) + \\sum_i \\alpha_i \\\\\n",
    "\\alpha_i \\geq 0,\\quad \\forall i\n",
    "$$\n",
    "\n",
    "Putting the derivatives equal to zero we get:\n",
    "$$\n",
    "w = \\sum_i \\alpha_i y_i x_i, \\quad \\sum_i \\alpha_i y_i = 0 \\\\\n",
    "$$\n",
    "\n",
    "In order to solve this maximization problem we have to switch to its dual formulation. Substituting the gradient and the constraint in the lagrangian we obtain:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\alpha) = \\sum_i \\alpha_i - \\frac{1}{2} \\sum_j \\sum_i y_j y_i \\alpha_j \\alpha_i  x_j \\cdot x_i   \n",
    "$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "\\alpha_i \\geq 0, \\quad \\sum_i \\alpha_i y_i = 0\n",
    "$$\n",
    "\n",
    "This is a simple quadratic form in the vector alpha. $w$ does not appear in optimization so it is only the result (that is I find alphas and then compute $w$).\n",
    "\n",
    "The solution of this optimization is quadratic programming. There are packages already available for solving quadratic programming problems, but we have to switch to a minimization problem. This is easily done by changing the sign of the equation. \n",
    "\n",
    "$$\n",
    "min_\\alpha \\quad  \\frac{1}{2} \\alpha \\cdot Q \\alpha - 1 \\cdot \\alpha\n",
    "$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "\\alpha_i \\geq 0, \\quad \\alpha \\cdot y = 0\n",
    "$$\n",
    "\n",
    "where Q is the matrix of quadratic coefficients (and the vector $-1$ is the linear term):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/quadratic_svm.png\"  alt=\"Margins\" height=\"500\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the quadratic programming package will take the matrix of coefficient and return the vector of alphas that minimize that quantity. The vector of alphas has the same lenght as the number of examples. The vector comes with a surprise, most of the alphas are zero!\n",
    "\n",
    "Now we want to get the solution, that is the vector of $w$, remember? Our separating hyperplane. How do we get that? By plugging alphas in the equation $w = \\sum_i \\alpha_i y_i x_i$\n",
    "\n",
    "The problem formulation has a nice condition, the quantity:\n",
    "\n",
    "$$\\alpha_i ( y_i (x_i \\cdot w + b) - 1) = 0$$\n",
    "\n",
    "so either the alpha is zero or the remaining term is zero! If the other term is positive, we are talking about an interior point, this equation guaranties that the corresponding alpha is zero. If in the other case alpha is positive the corresponding point is called **support vector**!\n",
    "\n",
    "$\\alpha_i > 0 \\implies x_i$ is a **support vector**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/svm.png\"  alt=\"Margins\" height=\"500\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Kernel Trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This formulation albeit interesting leaves us with one question. How do I apply SVM to the nonlinear case? \n",
    "\n",
    "Recall linear regression. In order to go nonlinear we had to transform the features. That is we passed from a feature space $\\mathcal{X}$ to a feature space $\\mathcal{Z}$. Can we apply the same transformation to the SVM? How does the problem formulation changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/non_linear_svm.png\"  alt=\"Margins\" height=\"500\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathcal{L}(\\alpha) = \\sum_i \\alpha_i - \\frac{1}{2} \\sum_j \\sum_i y_j y_i \\alpha_j \\alpha_i  z_j \\cdot z_i$$\n",
    "\n",
    "Suppose that the new space has higher dimension. Does it change the equation? No, because it is an inner product. We have only one number at the end! The number of alphas (the number of data points) remains the same. The $w$ however will belong to the $\\mathcal{Z}$ space. Do I have also the support vector in the $\\mathcal{X}$? They are not support vector any more, they are called \"pre-images\" of support vector (they are the closest to the margin) but the margin is maintained in the $\\mathcal{Z}$ space.\n",
    "\n",
    "The nice thing about this is: we don't need to compute the vectors $z_i$ and $z_j$ in the $\\mathcal{Z}$ space but only the dot product. So the mathematical computation involve $x_i$ and $x_j$ and gives the correct result in $\\mathcal{Z}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkz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\nXtzyAcMmfQRio6QIAIoAAQAAAAAAAAAAH//Z\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"420\"\n",
       "            src=\"https://www.youtube.com/embed/3liCbRZPrZA\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fa1b2cdce48>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('3liCbRZPrZA', width=800, height=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Soft margin SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 SVM for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SVC and NuSVC` are similar methods, but accept slightly different sets of parameters and have different mathematical formulations (see section Mathematical formulation). `LinearSVC` is another implementation of Support Vector Classification for the case of a linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bokeh.plotting as bk\n",
    "bk.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn import svm, datasets, preprocessing, neighbors, model_selection\n",
    "\n",
    "d = datasets.load_iris()  \n",
    "X = pd.DataFrame(d.data, columns=d.feature_names)\n",
    "y = d.target\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "h = .02               # step size in the mesh\n",
    "C = 1.0               # SVM regularization parameter\n",
    "\n",
    "std_svc = svm.SVC(kernel='linear', C=C).fit(X,y)\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C).fit(X,y)\n",
    "pol_svc = svm.SVC(kernel='poly', degree=3, C=C).fit(X,y)\n",
    "lin_svc = svm.LinearSVC(C=C).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import addutils.palette as pal\n",
    "import seaborn as sns\n",
    "from bokeh.models.mappers import LinearColorMapper\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xs = np.arange(x_min, x_max, h*2)\n",
    "ys = np.arange(y_min, y_max, h*2)\n",
    "xx, yy = np.meshgrid(xs, ys)\n",
    "xx = xx.ravel()\n",
    "yy = yy.ravel()\n",
    "\n",
    "titles = ['SVC with linear kernel',\n",
    "          'SVC with RBF kernel',\n",
    "          'SVC with polynomial (degree 3) kernel',\n",
    "          'LinearSVC (linear kernel)']\n",
    "\n",
    "grid = []\n",
    "palette = list(map(pal.to_hex, sns.color_palette('Paired', 6)))\n",
    "palette_dots = palette[1::2]    # colours in odd indices \n",
    "palette_patches = palette[::2]  # colours in even indices\n",
    "# Bokeh understands the mapping interval for the colors as open on the high side.\n",
    "# So we have to customize the color mapper, and raise the upper limit a bit\n",
    "# to prevent Bokeh from discarding any colours. \n",
    "# max(Z) is 2, so 2.1 is fine for the upper limit.\n",
    "patches_cmapper = LinearColorMapper(low=0, high=2.1, palette=palette_patches)\n",
    "\n",
    "for i, clf in enumerate((std_svc, rbf_svc, pol_svc, lin_svc)):\n",
    "    # Plot the decision boundary assigning a color to each point in the mesh\n",
    "    Z = clf.predict(np.c_[xx, yy])\n",
    "    Z = Z.reshape((ys.size, xs.size))\n",
    "    \n",
    "    # Plot the training points\n",
    "    fig = bk.figure(plot_width=360, plot_height=280, title=titles[i],\n",
    "                   x_range=(x_min, x_max), y_range=(y_min, y_max))\n",
    "    fig.title.text_font_size = '10pt'\n",
    "    fig.axis.major_label_text_color = None\n",
    "    fig.axis.major_tick_line_color = None\n",
    "    fig.axis.minor_tick_line_color = None\n",
    "    fig.image(image=[Z*0.99 + 0.1], x=[x_min], y=[y_min], \n",
    "              dw=[x_max-x_min], dh=[y_max-y_min],\n",
    "              color_mapper=patches_cmapper)\n",
    "    fig.scatter(X[:, 0], X[:, 1], size=6,\n",
    "                line_color='black', line_alpha=0.5,\n",
    "                fill_color=[ palette_dots[j] for j in y ])\n",
    "    grid.append(fig)\n",
    "    \n",
    "bk.show(bk.gridplot([[grid[0], grid[1]], [grid[2], grid[3]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 SVM for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method of Support Vector Classification can be extended to solve regression problems. This method is called Support Vector Regression.\n",
    "\n",
    "The model produced by support vector classification (as described above) depends only on a subset of the training data, because the cost function for building the model does not care about training points that lie beyond the margin. Analogously, the model produced by Support Vector Regression depends only on a subset of the training data, because the cost function for building the model ignores any training data close to the model prediction.\n",
    "\n",
    "As with classification classes, the fit method will take as argument vectors X, y, only that in this case y is expected to have floating point values instead of integer values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = [[0, 0], [2, 2]]\n",
    "y = [0.5, 2.5]\n",
    "svm_svr = svm.SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
    "                  epsilon=0.1, gamma='auto', kernel='rbf',\n",
    "                  shrinking=True, tol=0.01, verbose=False)\n",
    "svm_svr.fit(X, y) \n",
    "svm_svr.predict([[1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Regression (SVR) using linear and non-linear kernels:** this is a simple example of 1D regression using linear, polynominial and RBF kernels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate data and add noise to target\n",
    "X = np.sort(5 * np.random.rand(40, 1), axis=0)\n",
    "y = np.sin(X).ravel()\n",
    "y[::5] += 3 * (0.5 - np.random.rand(8))\n",
    "\n",
    "###############################################################################\n",
    "# Fit regression model\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr_lin = SVR(kernel='linear', C=1e3)\n",
    "svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "y_rbf = svr_rbf.fit(X, y).predict(X)\n",
    "y_lin = svr_lin.fit(X, y).predict(X)\n",
    "y_poly = svr_poly.fit(X, y).predict(X)\n",
    "\n",
    "###############################################################################\n",
    "# look at the results\n",
    "fig = bk.figure(plot_width=600, plot_height=500, title=\"Support Vector Regression\")\n",
    "fig.title.text_font_size = '12pt'\n",
    "fig.scatter(X[:,0], y, color='black', legend='data', size=8)\n",
    "fig.line(X[:,0], y_rbf, color='green', legend='RBF model')\n",
    "fig.line(X[:,0], y_lin, color='red', legend='Linear model')\n",
    "fig.line(X[:,0], y_poly, color='blue', legend='Polynomial model')\n",
    "fig.xaxis.axis_label = 'data'\n",
    "fig.yaxis.axis_label = 'target'\n",
    "fig.axis.axis_label_text_font_size = '11pt'\n",
    "bk.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Visit [www.add-for.com](<http://www.add-for.com/IT>) for more tutorials and updates.\n",
    "\n",
    "This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:addtrain]",
   "language": "python",
   "name": "conda-env-addtrain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
