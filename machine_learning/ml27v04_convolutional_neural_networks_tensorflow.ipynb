{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import addutils.toc ; addutils.toc.js(ipy_notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from time import time\n",
    "from IPython.display import Image, HTML, YouTubeVideo\n",
    "import math\n",
    "from addutils import css_notebook\n",
    "from scipy import ndimage\n",
    "from skimage import data\n",
    "from utilities import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import functools\n",
    "import os\n",
    "import pickle\n",
    "css_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import bokeh.plotting as bk\n",
    "from bokeh.io import push_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import ColumnDataSource\n",
    "bk.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks have gained much attention in the past few years, because they work very well in image processing, but nowadays are applyed to many Deep Learning tasks.\n",
    "\n",
    "The fundamental difference between fully connected and convolutional neural networks is the connection between consecutive layers. In fully connected network each neuron is connected to all neuron in the previous layer. We sa that in previous notebook. In a convolutional layer instead each neuron is connected to a (typically small) number of neurons in the previous layer. Furthermore all neurons in the same layer are coonected to the previous layer in the same way, they have the exact same way, with the same weights. This operation is known as convolution and in a nutshell it means applying a small filter across an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('images/WeightSharing.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** introduction to vision and motivation for concolutional layers: invariance, abstraction, and so on.\n",
    "\n",
    "Convolutional neural networks use three basic ideas: **local receptive fields**, **shared weights**, and **pooling**. Let's look at each of these ideas in turn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Local Receptive Fields and Shared Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the fully-connected layers shown earlier, the inputs were depicted as a vertical line of neurons. In a convolutional net, it'll help to think instead of the inputs as a 28×28 square of neurons, whose values correspond to the 28×28 pixel intensities we're using as inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('images/receptive.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will connect the input pixels to a layer of hidden neurons. But we don't connect every input pixel to every hidden neuron. Instead, we only make connections in small, localized regions of the input image.\n",
    "\n",
    "To be more precise, each neuron in the first hidden layer will be connected to a small region of the input neurons, say, for example, a 5×5 region, corresponding to 25 input pixels. That region in the input image is called the **local receptive field** for the hidden neuron. I've shown the local receptive field being moved by one pixel at a time. In fact, sometimes a different stride length is used. For instance, we might move the local receptive field 2 pixels to the right (or down), in which case we'd say a stride length of 2 is used. \n",
    "\n",
    "Each hidden neuron has a bias and 5×5 weights connected to its local receptive field. What I did not yet mention is that we're going to use the same weights and bias for each of the 24×24 hidden neurons. This means that all the neurons in the first hidden layer detect exactly the same feature just at different locations in the input image. They **Share weights and biases**. For this reason, we sometimes call the map from the input layer to the hidden layer a **feature map**. We call the weights defining the feature map the shared weights. And we call the bias defining the feature map in this way the shared bias. The shared weights and bias are often said to define a kernel or filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Image('images/feature_map.png', width=700, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** use 3D video of convolution filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is a filter useful? **TODO:** brief history of traditional computer vision task. Handcrafted filter and features and SVM combination.\n",
    "\n",
    "Let's see how filter works. We will implement two basic filters, a gaussian filter and a gabor filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ksize = 100\n",
    "x = np.linspace(-3, 3, ksize)\n",
    "y = np.exp(-np.power(x - 0, 2.) / (2 * np.power(1, 2.)))\n",
    "fig = bk.figure(plot_width=400, plot_height=250, title=None)\n",
    "fig.line(x, y)\n",
    "bk.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a two-dimensional filter by multiplying a column vector gaussian by a row vector gaussian to create a matrix, that will be our filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_kernel = np.dot(np.atleast_2d(y).T, np.atleast_2d(y))\n",
    "fig = bk.figure(x_range=(0, 1), y_range=(0, 1), \n",
    "                plot_width=300, plot_height=300, title=None)\n",
    "fig.image(image=[gaussian_kernel], x=0, y=0, dw=1, dh=1, palette=\"Plasma256\")\n",
    "bk.show(fig)\n",
    "print(gaussian_kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data.camera().astype(np.float32)\n",
    "fig = bk.figure(x_range=(0, 1), y_range=(0, 1), \n",
    "                plot_width=300, plot_height=300, title=None)\n",
    "fig.image(image=[np.flip(img, axis=0)], x=0, y=0, dw=1, dh=1, palette=\"Greys256\")\n",
    "bk.show(fig)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved = ndimage.convolve(img, gaussian_kernel, mode='constant', cval=0.0)\n",
    "fig = bk.figure(x_range=(0, 1), y_range=(0, 1), \n",
    "                plot_width=300, plot_height=300, title=None)\n",
    "fig.image(image=[np.flip(convolved, axis=0)], x=0, y=0, dw=1, dh=1, palette=\"Greys256\")\n",
    "bk.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, ksize)\n",
    "y = np.sin(x)\n",
    "fig = bk.figure(plot_width=400, plot_height=250, title=None)\n",
    "fig.line(x, y)\n",
    "bk.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones((1, ksize))\n",
    "wave = np.dot(np.atleast_2d(y).T, ones)\n",
    "gabor_filter = np.dot(wave, gaussian_kernel)\n",
    "fig = bk.figure(x_range=(0, 1), y_range=(0, 1), \n",
    "                plot_width=300, plot_height=300, title=None)\n",
    "fig.image(image=[gabor_filter], x=0, y=0, dw=1, dh=1, palette=\"Plasma256\")\n",
    "bk.show(fig)\n",
    "print(gaussian_kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved = ndimage.convolve(img, gabor_filter, mode='constant', cval=0.0)\n",
    "fig = bk.figure(x_range=(0, 1), y_range=(0, 1), \n",
    "                plot_width=300, plot_height=300, title=None)\n",
    "fig.image(image=[np.flip(convolved, axis=0)], x=0, y=0, dw=1, dh=1, palette=\"Greys256\")\n",
    "bk.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A big advantage of sharing weights and biases is that it greatly reduces the number of parameters involved in a convolutional network. For each feature map we need 25=5×5 shared weights, plus a single shared bias. So each feature map requires 26 parameters. If we have 32 feature maps that's a total of 32×26=832 parameters defining the convolutional layer. By comparison, suppose we had a fully connected first layer, with 784=28×28 input neurons, and a relatively modest 32 hidden neurons, as we used in many of the examples earlier in the book. That's a total of 784×32 weights, plus an extra 32 biases, for a total of 25,088 parameters. In other words, the fully-connected layer would have more than 30 times as many parameters as the convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('images/cnn.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the convolutional layers just described, convolutional neural networks also contain pooling layers. Pooling layers are usually used immediately after convolutional layers. What the pooling layers do is simplify the information in the output from the convolutional layer. Pool layers perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [14x14x32].\n",
    "\n",
    "Max pooling outputs the maximum of the input in each region of a predefined size (here 2×2). The stride argument controls by how much we slide the pooling grids across the picture. Setting the pooling to a 2×2 grid with strides equal 2 means that the output of the pooling will be exactly one-half of the height and width of the original, and in total one-quarter of the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('images/maxpool.jpeg', width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main motivations for this function are both technical and theoretical. For the technical aspect, pooling reduces the size of the data to be processed and in turn it reduces the number of overall parameters in the model, especially if we use fully connected layers after the convolutional ones. The theoretical aspect instead is that we would like the feature maps not to care about small changes in position in an image. For instance, a feature looking for eyes in the top-right part of an image should not change too much if we move the camera a bit to the right when taking the picture, moving the eyes slightly to the center of the image. Aggregating the feature maps spatially allows the model to overcome such variability, capturing some form of invariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('wO6AAq3uE-w', width=600, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 CNN for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('example_data/MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The MNIST dataset has 10 classes, representing the digits 0 through 9.\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# The MNIST images are always 28x28 pixels.\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('images/tf_mnist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the usual placeholder for the input examples and associated labels, as well as two helper functions to construct weight variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** use get_variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape of the input so it resemble a 2D image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now implement our first layer. It will consist of convolution, followed by max pooling. The convolutional will compute 32 features for each 5x5 patch. Its weight tensor will have a shape of [5, 5, 1, 32]. The first two dimensions are the patch size, the next is the number of input channels, and the last is the number of output channels. We will also have a bias vector with a component for each output channel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convolve x_image with the weight tensor, add the bias, apply the ReLU function, and finally max pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build a deep network, we stack several layers of this type. The second layer will have 64 features for each 5x5 patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, a fully connected layer that is able to combine previous layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to mention is regularization we applied dropout to prevent overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last stage compute probability and assign to each example a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_conv, labels=y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STEPS = 1000\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(STEPS):\n",
    "    batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], \n",
    "                                                  y_: batch[1], \n",
    "                                                  keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test accuracy {}'.format(accuracy.eval(feed_dict={x: mnist.test.images, \n",
    "                                                  y_: mnist.test.labels, \n",
    "                                                  keep_prob: 1.0})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** use tensorboard to plot train validation test and images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Advanced Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 CIFAR 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10 is another dataset used to benchmarking computer vision and machine learning algorithms. CIFAR10 is a set of 60,000 color images of size 32×32 pixels, each belonging to one of ten categories: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck. Unlike MNIST the images are RGB. We are going to use an utility function to download the cifare dataset. The dataset is approximately 170 MByte.\n",
    "\n",
    "**TODO:** explain dataset better. Use Tensorflow API to download and use dataset, explain dataset API of TF. Rename Section. Download and use tensorflow/models. Explain tfrecords. Plot cifar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10.data_path = \"example_data/CIFAR-10/\"\n",
    "cifar10.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = cifar10.load_class_names()\n",
    "images_train, cls_train, labels_train = cifar10.load_training_data()\n",
    "images_test, cls_test, labels_test = cifar10.load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set: {}\".format(len(images_train)))\n",
    "print(\"Test set: {}\".format(len(images_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an helper function for taking random batches from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch(batch_size):\n",
    "    # Number of images in the training-set.\n",
    "    num_images = len(images_train)\n",
    "\n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=batch_size,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random images and labels.\n",
    "    x_batch = images_train[idx, :, :, :]\n",
    "    y_batch = labels_train[idx, :]\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None, dim=9):\n",
    "    fig, axes = plt.subplots(int(np.sqrt(dim)), int(np.sqrt(dim)), figsize=(9,9))\n",
    "    fig.subplots_adjust(hspace=.6, wspace=.3)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i, :, :, :])    \n",
    "        # Name of the true class.\n",
    "        cls_true_name = class_names[cls_true[i]]\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true_name)\n",
    "        else:\n",
    "            # Name of the predicted class.\n",
    "            cls_pred_name = class_names[cls_pred[i]]\n",
    "            xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "  \n",
    "    #fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have an example of a 9 images sampled from the training set, with corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = images_test[0:9]\n",
    "# Get the true classes for those images.\n",
    "cls_true = cls_test[0:9]\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(x, shape):\n",
    "    W_conv = weight_variable(shape)\n",
    "    b_conv = bias_variable([shape[-1]])\n",
    "    return tf.nn.relu(conv2d(x, W_conv) + b_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_layer(h, shape):\n",
    "    W_fc = weight_variable(shape)\n",
    "    b_fc = bias_variable([shape[-1]])\n",
    "\n",
    "    h_flat = tf.reshape(h, [-1, shape[0]])\n",
    "    return tf.matmul(h_flat, W_fc) + b_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)\n",
    "\n",
    "conv1 = conv_layer(x, shape=[5, 5, 3, 32])\n",
    "conv1_pool = max_pool_2x2(conv1)\n",
    "\n",
    "conv2 = conv_layer(conv1_pool, shape=[5, 5, 32, 64])\n",
    "conv2_pool = max_pool_2x2(conv2)\n",
    "conv2_flat = tf.reshape(conv2_pool, [-1, 8 * 8 * 64])\n",
    "\n",
    "full_1 = tf.nn.relu(full_layer(conv2_flat, [8 * 8 * 64, 1024]))\n",
    "full1_drop = tf.nn.dropout(full_1, keep_prob=keep_prob)\n",
    "\n",
    "y_conv = full_layer(full1_drop, [1024, 10])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_conv, \n",
    "                                                                       labels=y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy, global_step=global_step)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(sess, steps, batch_size, save_dir='temp/cifar_1', prob=0.5):\n",
    "    save_path = os.path.join(save_dir, 'checkpoint')\n",
    "    try:\n",
    "        print(\"Trying to restore last checkpoint\")\n",
    "        last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=save_dir)\n",
    "        saver.restore(sess, save_path=last_chk_path)\n",
    "        print(\"Restored checkpoint from:\", last_chk_path)\n",
    "    except:\n",
    "        print(\"Failed to restore checkpoint. Initializing variables instead.\")\n",
    "        sess.run(tf.global_variables_initializer())   \n",
    "        \n",
    "    for i in range(steps):\n",
    "        batch = random_batch(batch_size)\n",
    "        global_i, _ = sess.run([global_step, train_step], feed_dict={x: batch[0], \n",
    "                                                                     y_: batch[1], \n",
    "                                                                     keep_prob: prob})\n",
    "        if (global_i % 100 == 0)  or (i == steps - 1):\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={x:batch[0],\n",
    "                                                           y_: batch[1],\n",
    "                                                           keep_prob: 1.0})\n",
    "            print(\"step {}, training accuracy {}\".format(global_i, train_accuracy))\n",
    "            \n",
    "        if (global_i % 1000 == 0)  or (i == steps - 1):\n",
    "            saver.save(sess, save_path=save_path, global_step=global_step)\n",
    "            print(\"saved checkpoint\")\n",
    "\n",
    "    acc = sess.run(accuracy, feed_dict={x: images_test, y_: labels_test, keep_prob: 1.0})\n",
    "    print('test accuracy {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STEPS = 1000\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "with tf.Session() as sess:\n",
    "    optimize(sess, STEPS, BATCH_SIZE)\n",
    "print('optimization time: {}'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.data is a library that helps defining input pipelines. \n",
    "\n",
    "**TODO:** get tensorflow model repository and get cifar10 data in slim subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset('example_data/cifar10_train.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in tf.python_io.tf_record_iterator(\"example_data/cifar10_train.tfrecord\"):\n",
    "    result = tf.train.Example.FromString(example)\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    features = {\"image/encoded\": tf.FixedLenFeature((), tf.string, default_value=\"\"), \n",
    "                \"image/class/label\": tf.FixedLenFeature((), tf.int64, default_value=0)}\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    return (tf.image.convert_image_dtype(tf.image.decode_png(parsed_features[\"image/encoded\"]), \n",
    "                                         dtype=tf.float32), \n",
    "            parsed_features[\"image/class/label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(_parse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "images, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    image, label = sess.run([images, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(image, label, dim=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Manage TensorFlow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lazy_property(function):\n",
    "    attribute = '_lazy_' + function.__name__\n",
    "    \n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def wrapper(self):\n",
    "        if not hasattr(self, attribute):\n",
    "            setattr(self, attribute, function(self))\n",
    "        return getattr(self, attribute)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _parse_function_augmented(example_proto):\n",
    "    features = {\"image/encoded\": tf.FixedLenFeature((), tf.string, default_value=\"\"), \n",
    "                \"image/class/label\": tf.FixedLenFeature((), tf.int64, default_value=0)}\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    images, labels = parsed_features[\"image/encoded\"], parsed_features[\"image/class/label\"]\n",
    "    images = tf.image.convert_image_dtype(tf.image.decode_png(images), dtype=tf.float32)\n",
    "    images = tf.image.flip_left_right(images)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnModel:\n",
    "    def __init__(self, \n",
    "                 cnn_layers, \n",
    "                 fc_layers, \n",
    "                 train_file,\n",
    "                 test_file,\n",
    "                 batch_size=128, \n",
    "                 save_dir='temp/cifar_2', \n",
    "                 shape=(32, 32),\n",
    "                 channels=3,\n",
    "                 n_classes=10):\n",
    "        self.save_dir = save_dir\n",
    "        self.save_path = os.path.join(save_dir, 'checkpoint')\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        self.channels = channels\n",
    "        self.height, self.width = shape\n",
    "        self.train_file = train_file\n",
    "        self.test_file = test_file\n",
    "        \n",
    "        self.filename = tf.placeholder(tf.string, shape=None)\n",
    "        self.images, self.labels = self._dataset()\n",
    "        \n",
    "        self.cnn_layers = cnn_layers\n",
    "        self.fc_layers = fc_layers\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        self.global_step = tf.Variable(initial_value=0, \n",
    "                                       name='global_step', \n",
    "                                       trainable=False) # use get_variable\n",
    "        self._layers = []\n",
    "        self.cost\n",
    "        self.accuracy\n",
    "        self.optimize\n",
    "        self.prediction\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "    def _dataset(self): # add augment operations \n",
    "        dataset = tf.data.TFRecordDataset(self.filename)\n",
    "        dataset = dataset.map(_parse_function, num_parallel_calls=64)\n",
    "        #augmented = tf.data.TFRecordDataset(self.filename)\n",
    "        #augmented = augmented.map(_parse_function_augmented, num_parallel_calls=64)\n",
    "        #dataset = dataset.concatenate(augmented)\n",
    "        dataset = dataset.shuffle(10000)\n",
    "        dataset = dataset.batch(self.batch_size)\n",
    "        self.dataset = dataset.prefetch(1)\n",
    "        self.iterator = self.dataset.make_initializable_iterator()\n",
    "        return self.iterator.get_next()\n",
    "    \n",
    "    @lazy_property\n",
    "    def prediction(self):\n",
    "        return tf.nn.softmax(self.forward)\n",
    "\n",
    "\n",
    "    @lazy_property\n",
    "    def forward(self):\n",
    "        pool = 0\n",
    "        for l in self.cnn_layers:\n",
    "            if len(self._layers) == 0:\n",
    "                self._layers.append(conv_layer(self.images, \n",
    "                                               shape=[5, 5, self.channels, l]))\n",
    "                self._layers.append(max_pool_2x2(self._layers[-1]))\n",
    "                pool += 1\n",
    "            else:\n",
    "                _, _, _, feature_maps = self._layers[-1].get_shape().as_list()\n",
    "                self._layers.append(conv_layer(self._layers[-1], \n",
    "                                               shape=[5, 5, feature_maps, l]))\n",
    "                self._layers.append(max_pool_2x2(self._layers[-1]))\n",
    "                pool += 1\n",
    "\n",
    "        _, _, _, feature_maps = self._layers[-1].get_shape().as_list()\n",
    "        h = self.height//(2**pool)\n",
    "        self._layers.append(tf.reshape(self._layers[-1], [-1, h * h * feature_maps]))\n",
    "        for i, l in enumerate(self.fc_layers):\n",
    "            if i == 0:\n",
    "                self._layers.append(tf.nn.relu(full_layer(self._layers[-1], \n",
    "                                                          [h * h * feature_maps, l])))\n",
    "                self._layers.append(tf.nn.dropout(self._layers[-1], \n",
    "                                                  keep_prob=self.keep_prob))\n",
    "            else:\n",
    "                self._layers.append(tf.nn.relu(full_layer(self._layers[-1], \n",
    "                                                          [self.fc_layers[i-1], l])))\n",
    "                self._layers.append(tf.nn.dropout(self._layers[-1], \n",
    "                                                  keep_prob=self.keep_prob))\n",
    "\n",
    "        y_conv = full_layer(self._layers[-1], [l, self.n_classes])\n",
    "\n",
    "        return y_conv\n",
    "\n",
    "    @lazy_property\n",
    "    def cost(self):\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.forward, \n",
    "                                                                                      labels=self.labels))\n",
    "        return cross_entropy\n",
    "\n",
    "    @lazy_property\n",
    "    def accuracy(self):\n",
    "        correct_prediction = tf.equal(tf.argmax(self.forward, 1), \n",
    "                                      self.labels)\n",
    "        return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    @lazy_property\n",
    "    def optimize(self):\n",
    "        return tf.train.AdamOptimizer(1e-3).minimize(self.cost, \n",
    "                                                     global_step=self.global_step)\n",
    "    \n",
    "    def fit(self, epochs=1, prob=0.5):\n",
    "        with tf.Session() as sess:\n",
    "            try:\n",
    "                print(\"Trying to restore last checkpoint\")\n",
    "                last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=self.save_dir)\n",
    "                saver.restore(sess, save_path=last_chk_path)\n",
    "                print(\"Restored checkpoint from:\", last_chk_path)\n",
    "            except:\n",
    "                print(\"Failed to restore checkpoint. Initializing variables instead.\")\n",
    "                sess.run(tf.global_variables_initializer())   \n",
    "\n",
    "            for i in range(epochs):\n",
    "                sess.run(self.iterator.initializer, feed_dict={self.filename: self.train_file})\n",
    "                feed_dict = {self.keep_prob: prob}\n",
    "                try:\n",
    "                    while True:\n",
    "                        global_i, _ = sess.run([self.global_step, self.optimize], \n",
    "                                               feed_dict=feed_dict)\n",
    "                        if (global_i % 100 == 0):\n",
    "                            feed_dict[self.keep_prob] = 1.0\n",
    "                            train_accuracy = sess.run(self.accuracy, feed_dict=feed_dict)\n",
    "                            print(\"step {}, training accuracy {}\".format(global_i, train_accuracy))\n",
    "                        if (global_i % 1000 == 0):\n",
    "                            saver.save(sess, save_path=self.save_path, global_step=self.global_step)\n",
    "                            print(\"saved checkpoint\")\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "            return\n",
    "        \n",
    "    def predict_accuracy(self):\n",
    "        with tf.Session() as sess:\n",
    "            try:\n",
    "                print(\"Trying to restore last checkpoint\")\n",
    "                last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=self.save_dir)\n",
    "                saver.restore(sess, save_path=last_chk_path)\n",
    "                print(\"Restored checkpoint from:\", last_chk_path)\n",
    "            except:\n",
    "                print(\"Failed to restore checkpoint. Initializing variables instead.\")\n",
    "                sess.run(tf.global_variables_initializer())   \n",
    "                \n",
    "            sess.run(self.iterator.initializer, feed_dict={self.filename: self.test_file})\n",
    "            feed_dict = {self.keep_prob: 1.0}\n",
    "            # aggiungere while True e try catch con una singola epoca\n",
    "            acc = sess.run(self.accuracy, feed_dict=feed_dict)\n",
    "            return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = CnnModel([32, 64], [1024], \n",
    "                    train_file='example_data/cifar10_train.tfrecord', \n",
    "                    test_file='example_data/cifar10_test.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "model.fit(6)\n",
    "print('Training time: {}'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "print(model.predict_accuracy())\n",
    "print('Prediction time: {}'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = CnnModel([32, 64, 128], [4096, 1024], save_dir='temp/cifar_3',\n",
    "                    train_file='example_data/cifar10_train.tfrecord', \n",
    "                    test_file='example_data/cifar10_test.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "model.fit(3)\n",
    "print('Training time: {}'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "print(model.predict_accuracy())\n",
    "print('Prediction time: {}'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Usare slim e una rete preallenata per fare l'esempio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "Visit [www.add-for.com](<http://www.add-for.com/IT>) for more tutorials and updates.\n",
    "\n",
    "This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
