{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Basic concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id='toc-container'><script type='text/javascript'>\n",
       "$(function() {\n",
       "    function regenTOC(){\n",
       "        element = $(\"#toc-container\");\n",
       "\n",
       "\tvar toc = document.createElement(\"div\");\n",
       "\t$(toc).attr(\"class\", \"table-of-contents\");\n",
       "\n",
       "\tvar curLevel = 0;\n",
       "\tvar containerStack = [toc];\n",
       "\tvar levelOfTag = {\"h2\": 1, \"h3\": 2, \"h4\": 3, \"h5\": 4};\n",
       "\n",
       "\tfunction pushLevel() {\n",
       "            var list = document.createElement(\"ul\");\n",
       "            containerStack.push(list);\n",
       "            curLevel++;\n",
       "\t}\n",
       "\t\n",
       "\tfunction popLevel() {\n",
       "            var lastContainer = containerStack.pop();\n",
       "            $(lastContainer).appendTo(containerStack[containerStack.length - 1]);\n",
       "            curLevel--;\n",
       "\t}\n",
       "\t\n",
       "\t$(\".text_cell_render :header\").each(function (i, elem) {\n",
       "            var level = levelOfTag[ elem.tagName.toLowerCase() ];\n",
       "\n",
       "            if (level === undefined)\n",
       "\t\treturn;\n",
       "\n",
       "            while (curLevel < level)\n",
       "\t\tpushLevel();\n",
       "            while (curLevel > level)\n",
       "\t\tpopLevel();\n",
       "            \n",
       "            var listItem = document.createElement(\"li\");\n",
       "            var link = document.createElement(\"a\");\n",
       "            $(link)\n",
       "\t\t.text($(elem).contents().first().text()) // Remove the pilcrow sign\n",
       "\t\t.attr(\"href\", \"#\" + $(elem).attr(\"id\"))\n",
       "\t\t.appendTo(listItem);\n",
       "            $(listItem).appendTo(containerStack[containerStack.length - 1]);\n",
       "\t});\n",
       "\t\n",
       "\twhile (curLevel > 0)\n",
       "            popLevel();\n",
       "\n",
       "        $(\"<a class='btn-update' href='#'>Update</a>\")\n",
       "          .click(regenTOC).prependTo(toc);\n",
       "\n",
       "\t$(toc).prepend(\"<div class='title'>Contents</div>\")\n",
       "          .wrap(\"<div class='toc-headings'/>\");\n",
       "\n",
       "        $(element).empty();\n",
       "        $(element).append(toc);\n",
       "    }\n",
       "\n",
       "    if (typeof(IPython) !== 'undefined')\n",
       "        $([IPython.events]).on('notebook_loaded.Notebook', regenTOC);\n",
       "    regenTOC();\n",
       "});\n",
       "\n",
       "</script></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import addutils.toc ; addutils.toc.js(ipy_notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".text_cell_render @font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    width: 900px;\n",
       "    margin-left: 0% !important;\n",
       "    margin-right: 0%;\n",
       "}\n",
       "\n",
       "code {\n",
       "    font-size:10pt;\n",
       "}\n",
       "\n",
       ".text_cell_render  h1 {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:28pt;\n",
       "}\n",
       ".text_cell_render h2 {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:24pt;\n",
       "}\n",
       ".text_cell_render h3 {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:20pt;\n",
       "}\n",
       ".text_cell_render h4 {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:18pt;\n",
       "    margin-top:12px;\n",
       "    margin-bottom: 3px;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {\n",
       "    font-weight: 300;\n",
       "    font-size: 11pt;\n",
       "    color: rgb( 48, 48, 48 );\n",
       "    font-style: italic;\n",
       "    margin-bottom: .5em;\n",
       "    margin-top: 0.5em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render ul {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 90, 90, 90 );\n",
       "    font-size:11pt;\n",
       "    line-height: 185%;\n",
       "}\n",
       "\n",
       ".text_cell_render yp {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 90, 90, 90 );\n",
       "    font-size:11pt;\n",
       "}\n",
       "\n",
       ".text_cell_render strong {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 30, 30, 30 );\n",
       "    font-size:11pt;\n",
       "}\n",
       "\n",
       ".text_cell_render a:link {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:11pt;\n",
       "}\n",
       "\n",
       ".text_cell_render a:visited {\n",
       "    color:rgb( 10, 88, 126 );\n",
       "}\n",
       "\n",
       ".text_cell_render {\n",
       "    font-family: Helvetica, Courier, Computer Modern, \"Helvetica Neue\", Arial, Geneva, sans-serif;\n",
       "    color: rgb( 84, 84, 84 );\n",
       "    font-size:11pt;\n",
       "    line-height: 125%;\n",
       "    font-size: 100%;\n",
       "    width:800px;\n",
       "}\n",
       "\n",
       ".CodeMirror {\n",
       "    font-family: Courier, \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "}\n",
       "\n",
       ".warning {\n",
       "    color: rgb( 240, 20, 20 );\n",
       "}\n",
       "\n",
       "/* Pandas tables */\n",
       "/*\n",
       ".rendered_html td {\n",
       "    text-align: right;\n",
       "}\n",
       "*/\n",
       "\n",
       "table.dataframe td {\n",
       "    text-align: right;\n",
       "}\n",
       "\n",
       ".output .table-of-contents {\n",
       "    border: 1px #cecece solid;\n",
       "    background-color: #fafafa;\n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 5px;\n",
       "    padding-right: 15px;\n",
       "    padding-left: 0px;\n",
       "    margin-bottom: 20px;\n",
       "    display: inline-block;\n",
       "    position: relative;\n",
       "}\n",
       "\n",
       ".output .table-of-contents ul {\n",
       "    list-style-type: none;\n",
       "    padding-left: 20px;\n",
       "}\n",
       "\n",
       ".output .table-of-contents .title {\n",
       "    font-weight: bold;\n",
       "    font-height: 11pt;\n",
       "    padding-left: 20px; /* looks better if it's the same to the <ul> */\n",
       "}\n",
       "\n",
       ".output .table-of-contents .btn-update {\n",
       "    position: absolute;\n",
       "    float: right;\n",
       "    right: 11px;\n",
       "    top: 4px;\n",
       "    font-size: 9pt;\n",
       "}\n",
       "\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.display import Image\n",
    "from addutils import css_notebook\n",
    "css_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"c95125f4-ee4f-4eca-9152-50db9da28707\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"c95125f4-ee4f-4eca-9152-50db9da28707\");\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"c95125f4-ee4f-4eca-9152-50db9da28707\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'c95125f4-ee4f-4eca-9152-50db9da28707' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.7.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"c95125f4-ee4f-4eca-9152-50db9da28707\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"c95125f4-ee4f-4eca-9152-50db9da28707\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.plotting as bk\n",
    "bk.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Deep learning, cos'è tensorflow (breve storia) e perché è utile, utilizzo della GPU.\n",
    "\n",
    "The main argument we treat in this notebook is TensorFlow, a library for machine learning and deep learning recently open sourced by google. For more information please visit [TensorFlow](http://www.tensorflow.org).\n",
    "\n",
    "TensorFlow, is conceptually similar to theano; the computation is formally a graph, with nodes representing operations while edges representing tensors (multidimensional data) communicated between operations. According to TensorFlow web site, the flow of tensors through the graph is where TensorFlow gets its name. It is not intended to be only a neural network library but to perform any computation that can be expressed as a graph. TensorFlow automatic differentiation is especially suited for gradient based machine learning algorithms. The library is written in C++ and it has nice Python bindings. Moreover it can run both on CPU and GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires few additional packages. Please be sure to install them properly before running the notebook. \n",
    "\n",
    "We suggest to follows the steps outlined in: [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)\n",
    "\n",
    "In particular if you want to use this notebook on your laptop (*without* GPU support) we suggest to create an anaconda environment and follow pip installation process:\n",
    "\n",
    "- `conda create --name tf python=3.6.2`\n",
    "- install additional packages (addutils, pandas, scikit-learn, jupyter)\n",
    "- `source activate tf`\n",
    "- `pip install --upgrade tensorflow`\n",
    "\n",
    "These simple steps allow you to run the notebooks, although with poorer performance.\n",
    "\n",
    "**TODO:** Come installare CUDA e cudnn cosa sono e installare la versione con supporto per la GPU. Compilazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Tensorflow Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import tensorflow and show current version. At the moment of writing we are using tensorflow version 1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow represent computations as **graphs**. Nodes in the graph are called **ops** (operations). An op takes zero or more **Tensors** and produces zero or more Tensors as output. A Tensor is a multidimensional array with a specified type. The graph is a description of a computation, in order to actually execute the computation a graph must be launched in a **session**. A session exectue a specific graph on one of the available **devices** (that can be either CPUs or GPUs).\n",
    "\n",
    "In following paragraphs we will clarify these concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Computation Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow programs are usually structured into a construction phase, that assembles a graph, and an execution phase that uses a session to execute ops in the graph.\n",
    "\n",
    "For example, it is possible to represent and train a neural network in the construction phase, and then repeatedly execute a set of training ops in the graph in the execution phase.\n",
    "\n",
    "It is possibile to build a graph by starting with nodes that do not need any input, such as constant nodes. Then it is possible to use the output of the constant node as input to other operations. TensorFlow uses a default graph to which operations are added, the default graph is created empty as soon as tensorflow is imported. It is sufficient for most operations but it is also possible to manage multiple graphs with the `Graph` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.constant(4.)\n",
    "y = tf.constant(3.)\n",
    "product = tf.multiply(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The code creates three nodes: two constant and an operation (multiplication) that takes two inputs (the two constants) and produces an output (product). To actually procude an output is is necessary to run the graph in a session. \n",
    "\n",
    "What is the difference between this expression and a corresponding plain python code that multiply two constants? Try to print the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key idea is that `product` does not compute the product of x and y but rather add the product operator to a graph of computation that will be executed later. \n",
    "\n",
    "**Computation Graphs** allow us to implement ML algorithms by creating and executing operations that interacts with each others. The interaction between operations constitutes the graph. \n",
    "\n",
    "What is a graph in the end? It is a set of *nodes* (or vertices) interconnected by (directed) *edges*. Edges allow data to **flow** from one node to another. Each node represent an operation, that produces an ouput that is passed on in the graph. Operations can be of any kind, from math to logging operation (we will se more on this when we will use TensorBoard).\n",
    "\n",
    "The graph connectivity defines a set of node dependencies, TensorFlow is able to optimize the computation based on this dependencies. Being able to identify connectivities allows to distribute computation and avoid performing redundant computations on irrelevant portion of the graph.\n",
    "\n",
    "We can add other operations to the graph. For example we can do a sum after the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = tf.constant(8.)\n",
    "addition = tf.add(product, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next image represent the default graph for the operations defined before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQEAbABsAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0a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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "image/jpeg": {
       "height": 600,
       "width": 600
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('images/computation_graph_example.jpg', width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the name of the variables (x, y and product) should be regarded as the output of the operations and not the opration themselves. Note that for some arithmetic and logical operation it is possible to use operator overloading instead of using `tf.<operator>`. For example the multiplication could be written `product = x * y`.\n",
    "\n",
    "It is possible to create additional graphs and control how operations and variables get associated with them. `tf.Graph()` creates a new graph. To check which graph is currently se as default we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x7fb4ec702710>\n"
     ]
    }
   ],
   "source": [
    "g_default = tf.get_default_graph()\n",
    "print(g_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a new graph g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x7fb4ec702ef0>\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see they are diffrent objects. Also, given a node, we can see to which graph is associated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(x.graph is g)\n",
    "print(x.graph is g_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `with` statement we can control which graph is set as default and add new nodes to it. For example we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(g is tf.get_default_graph())\n",
    "\n",
    "with g.as_default():\n",
    "    print(g is tf.get_default_graph())\n",
    "    \n",
    "print(g_default is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Once the computation graph is defined we can use it in a **Session** to actually obtain the result. Session objects are part of TensorFlow API that are responsible for the communication between data and objects and compuational resources. The computation is performed with the method `run()` of the session object. Without arguments `Session` uses the default graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run([addition])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to close a session after last operation, to release computational resources; closing a session is done with the method `close()`. It is possible to use `with ... as  ...` statement, that takes care of releasing resources when computation is finished.\n",
    "\n",
    "Tensorflow translates the graph into executable operations and it distributes the computation automatically on available resources. It uses the available **GPU** for as many operations as possible.\n",
    "\n",
    "It is possible to use a **specific device** for a session with `with tf.device(\"/gpu:1\"):` statement. For example previous command execute the graph on the second GPU of the machine. Try to change the string and execute the code on CPU (or another GPU of your machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        result = sess.run([addition])\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the these example we requested a particular node of the graph, by passing it to the method `run()`. This is called **fetch** and the arguments of the function are the fetches. It is possible to fetch more than one variable by passing them simultaneously to the run() command (`session.run([var1, var2])`). The result is a list of values fetched. As we said earlier, TensorFlow computes only the necessary portion of the graph if we ask to compute only the product, only the output of node product is computed (involving only the nodes to which it depends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.0, 20.0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run([product, addition])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an interactive environment like IPython or Jupyter it could be useful to interleave graph construction and run operations, you can use `InteractiveSession`. The only difference with a regular `Session` is that an `InteractiveSession` installs itself as the default session on construction. The methods `Tensor.eval()` and `Operation.run()` will use that session to run ops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.    0.25  0.5   0.75  1.  ]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "c = tf.linspace(0.0, 1.0, 5)\n",
    "print(c.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.get_default_graph()\n",
    "operations = [op for op in g.get_operations()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Const',\n",
       " 'Const_1',\n",
       " 'Mul',\n",
       " 'Const_2',\n",
       " 'Add',\n",
       " 'LinSpace/start',\n",
       " 'LinSpace/stop',\n",
       " 'LinSpace/num',\n",
       " 'LinSpace']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[op.name for op in operations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running an operation makes tensorflow running all the operations required for the input of this operation, but doesn't return anything. It is also possible to get tensors and operations by name from a graph.\n",
    "\n",
    "Now we close interactive session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow uses **Tensors** to represents all data. Only tensors are passed between ops in the graph. Tensors are an n-dimensional arrays, and, in TensorFlow, are described with rank, shape and type. The rank its the number of dimensions (different from matrix rank), the shape is the number of elements for each dimension and the type is the data type assigned to the tensor.\n",
    "\n",
    "When we create an operation for example with tf.add(), the operation is a *node* added to the graph but the handle we get is the tensor that results from the operation. This handle is the *edge* of the graph and it passes (**flow**) the yet-to-be-computed result of the operation to other nodes.\n",
    "\n",
    "Tensors objects have attributes and operations. For example the tensor `x` is a tensor with no shape (actually shape 1x1) that is a scalar, and it's dtype is a float32:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors dtype can be specified at creation time or can be modified later using `tf.cast` operation. Tensor can be viewed as n-dimensional arrays. As we have already seen a $1 \\times 1$ tensor is a scalar, a $1 \\times n$ tensor is a vector, a $n \\times n$ tensor is a matrix, a $n \\times n \\times n$ tensor is a three dimensional array, and so on (it can be generalized to any dimension). As with dtypes, TensorFlow can infer automatically the dimension of a tensor object given the shape of the data. For example if we want to create a matrix with `tf.constant` and see what shape we get, we can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = tf.constant([[1,2,3], \n",
    "                 [4,5,6]])\n",
    "print(w.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other types of operations that generates number without user input are random number generation operators, linspace (as seen before), array of constant (one or zero values) and many others. They resemble the operations and API used by numpy. \n",
    "\n",
    "An important operation that we will use often is matrix multiplication. It is needed to perform operations like $Ax=b$, where $A$ is a matrix and $x$ is a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = tf.constant([[1,2,3],\n",
    "                 [4,5,6]])\n",
    "print(A.get_shape())\n",
    "x = tf.constant([[1],[0],[1]])\n",
    "print(x.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "b = tf.matmul(A,x)\n",
    "print(b.eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors have a name as well, it can be assigned at creation time or TensorFlow assign it for  you (as happened before). It can be displayed with method `name`. The name of the objec is simply the name of the operation followed by a colon and the index of that tensor in the output of the operation that produced it. If two or more operations exists, tensorflow add an underscore to its names followed by a progressive number to avoid tensors with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes can be useful, especially in complicated graphs, to group together related tensors, that belong to a certain portion of the graph for example. **Name scopes** are used for this purpose. Here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    a1 = tf.constant(4,dtype=tf.float64, name='variable_a1')\n",
    "    with tf.name_scope(\"group\"):\n",
    "        group_a1 = tf.constant(4,dtype=tf.int32,name='variable_a1')\n",
    "        group_a2 = tf.constant(4,dtype=tf.int32,name='variable_a2')\n",
    "\n",
    "print(a1.name)\n",
    "print(group_a1.name)\n",
    "print(group_a2.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Variables and Placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables** are used to maintain state accross executions of the graph. In this example `state` is initialized to zero and updated each time `update` is run. When using variables, they must be initialized after launching the graph, that is after creating a session. In order to initialize the variables it is necessary to add an init operation that must be run *before* all other operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print('state: ' + str(sess.run(state)))\n",
    "    for _ in range(5):\n",
    "        sess.run(update)\n",
    "        print('state: ' + str(sess.run(state)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `assign` is part of the computational graph as `add` and other operators. Variables are typically used to represent parameters of a model, for example in neural network they are used to store the weights matrix, that it is updated at every execution of the graph. Parameters are updated by the operations in the graph as the result of the optimization process. \n",
    "\n",
    "Variables can be initialized to random values, using a distribution (in the previous example it was initialized to zero). For example we can use a random normal distribution with given mean and standard deviation, as well as specify resulting shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_val = tf.random_normal((1,5), 0, 1)\n",
    "var = tf.Variable(init_val, name='var')\n",
    "\n",
    "print('tensor object: {}'.format(var))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    initialized_values = sess.run(var)\n",
    "    \n",
    "print('tensor values after init: {}'.format(initialized_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we run the code several times the output changes, but also the object changes (look at the name of the object!). A new variable is created every time `tf.Variable` method is called. We will see how to use this feature later on.\n",
    "\n",
    "So far we have covered how to store values in constant and use variable to update their values (these operations are calle *source* operations). TensorFlow provides also a method to pass a value to the variables with a **feed** mechanism. A feed replace the value of a tensor with the value that you provide. Tensorflow provides a special structure called **placeholder** for feeding input values. Placeholders have an optional shape parameter, that can be set to `None` meaning that the shape can be of any size (we will see that it is common for mini-batches later on). To feed the values we construct a dictionary whose keys correspond to placeholder variables and values can be list or numpy arrays to feed to each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = input1 * input2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([output], feed_dict={input1:[7.], input2:[2.]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variable declaered as placeholder expects a feed and generate an error if it is not supplied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Building Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now tensorflow is especially useful to train Machine Learning models. We will briefly sketch the workflow of building simple models. We will switch to more complex models (Neural Networks) later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Linear Regression example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most simple model to build is based on a target variable $y$ that we are trying to predict given input data $x$. We have a set of $x$ and $y$ values that we use to train the model. Suppose that $y$ is a vector with continuous values, we have a regression model that can be described with a simple equation: $f(x) = w^Tx + b$ and $y = f(x) + \\epsilon$, where \n",
    "$f(x)$ is a linear combination of our training data $x$, with a set of weights $w$ and an intercept $b$. The target $y$ is equal to $f(x)$ with added gaussian noise. \n",
    "\n",
    "We implement this simple regression with tensorflow. First we need to create the computational graph, then we will create some input date and train the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inputs\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=None)\n",
    "# parameters\n",
    "init_val = tf.random_normal((1, 3), 0, 1)\n",
    "W = tf.Variable(init_val, dtype=tf.float32, name='weights')\n",
    "b = tf.Variable(0, dtype=tf.float32, name='bias')\n",
    "# output\n",
    "linear_model = tf.matmul(W, tf.transpose(X)) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to train such a linear model? There is however a simple closed formula to solve a linear regression model, but we will define a loss function and an optimization operation, that will be inserted into the graph (it will be helpful later on when we will see Neural Networks). The loss function defines a method to evaluate model performance. The loss function defines a distance between the predicted values and the target values, and it is used as input to the optimization procedure that finds a set of parameters that minimize the loss function. The most common loss function is the Mean Squared Error (MSE), that finds the squared distance between a set of points and then averages the results over all points. The optimization operation is gradient descent that iteratively updates the weights in a way that decreases loss over time. The update rule is based on the gradient of the loss function. If the loss is a multivariate function of the weights $F(\\hat w)$, then in the neighborhood of some point $\\hat w_0$, the *steepest* direction of decrease of $F(\\hat w)$ is obtained by moving from $\\hat w_0$ in the direction of the negative gradient of $F$ at $\\hat w_0$. We will give more hints on the gradient descent algorithm and its variants when we will use it with Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss\n",
    "loss = tf.reduce_mean(tf.square(linear_model - y)) \n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a set of points to used for training and as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.random.randn(2000, 3)\n",
    "w_real = [0.3,0.5,0.1]\n",
    "b_real = -0.2\n",
    "\n",
    "noise = np.random.randn(2000) * 0.1\n",
    "y_real = np.matmul(w_real, data.T) + b_real\n",
    "target = y_real + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: spiegare i passi e aggiungere la linea reale e quella predetta! Usare range1d e linspace guardare i modelli lineari!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_STEPS = 10\n",
    "wb_ = []\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(0, sess.run([W, b]))\n",
    "    for step in range(NUM_STEPS):\n",
    "        sess.run(train, {X: data, y: target})\n",
    "        if ((step+1) % 5 == 0):\n",
    "            print(step+1, sess.run([W, b]))\n",
    "            wb_.append(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = bk.figure(plot_width=630, plot_height=300, title=None)\n",
    "fig.scatter(target, y_real, alpha=0.3)\n",
    "#fig.ray(x=0, y=0, angle=45, angle_units='deg', length=0, color='red')\n",
    "bk.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Classify Digits with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn to classify MNIST handwritten digit images into their correct label (0-9). MNIST is a standard dataset hosted on [Yann LeCun's website](https://www.tensorflow.org/versions/r0.11/tutorials/mnist/beginners/index.html). The digits have been size-normalized and centered in a fixed-size image.\n",
    "\n",
    "The importance of classical datasets is twofold. First they are good for people who want to try machine learning techniques while spending minimal efforts on preprocessing and formatting data. Second they are useful for comparing machine learning algorithms, since we know well how they work on these datasets.\n",
    "\n",
    "Each image is 28 pixels by 28 pixels, representing an handwritten number between 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image('images/mnist1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret this as a big array of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image('images/mnist2.png',  width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each image has 28 by 28 pixels, we get a 28x28 array. We can flatten each array into a 28∗28=784 dimensional vector. Each component of the vector is a value between zero and one describing the intensity of the pixel. Thus, we generally think of MNIST as being a collection of 784-dimensional vectors. Flattening the image may throw away information about the structure and it surely does. There are methods that look directly at the 2D image but will be covered in later tutorials.\n",
    "\n",
    "Now, we load the data and we see how it is organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('example_data/MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is split into three parts, one for training, one for testingand one for validation. Each dataset is an n-dimensional array with shape [number of examples, 784]. Each example is an image with associated a corresponding label, a number between 0 - 9 that represents the digit depicted in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The MNIST dataset has 10 classes, representing the digits 0 through 9.\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# The MNIST images are always 28x28 pixels.\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('train examples: ', mnist.train.num_examples)\n",
    "print('test examples: ', mnist.test.num_examples)\n",
    "print('validation examples: ', mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to classify the digits we will use an output layer with 10 units, one for each digits. For this reason our labels are encoded as \"one-hot vectors\". A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case the\n",
    "n-th digit will be represented as a vector which is 1 in the n-th dimension. For example, 3 would be [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]. Consequently, mnist.train.labels is a [55000, 10] array of floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mnist.train.labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a simple linear model for classification, the logistic regression; logistic regression outputs a probability for each class. In particular we will use a softmax classification for the case of multiple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image('images/logistic_function.png', height=\"500\", width=\"500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma(z) = \\frac{1}{1+e^{-z}} $$\n",
    "\n",
    "Where the $z$ in previous function has the value of $W^Tx+b$ and the output $c$ of this function is the probability of being in that class that is $P(Y=c \\mid X=x)$, given $x$ parametrized by $W$ and $b$.\n",
    "\n",
    "First we define two placeholder variables, one for the input $x$ the other for the (true) output $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, IMAGE_PIXELS])\n",
    "y = tf.placeholder(tf.int32, shape=[None, NUM_CLASSES])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first variable that must be optimized is called `weights` and is defined here as a TensorFlow variable that must be initialized with zeros and whose shape is `[IMAGE_PIXELS, NUM_CLASSES]`, so it is a 2-dimensional tensor (or matrix) with `IMAGE_PIXELS` rows and `NUM_CLASSES` columns.\n",
    "\n",
    "The second variable that must be optimized is called `biases` and is defined as a 1-dimensional tensor (or vector) of length `NUM_CLASSES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.zeros([IMAGE_PIXELS, NUM_CLASSES]))\n",
    "biases = tf.Variable(tf.zeros([NUM_CLASSES]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple mathematical model multiplies the images in the placeholder variable `x` with the `weights` and then adds the `biases`.\n",
    "\n",
    "The result is a matrix of shape `[num_images, NUM_CLASSES]` because `x` has shape `[num_images, IMAGE_PIXELS]` and `weights` has shape `[IMAGE_PIXELS, NUM_CLASSES]`, so the multiplication of those two matrices is a matrix with shape `[num_images, NUM_CLASSES]` and then the `biases` vector is added to each row of that matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = tf.matmul(x, weights) + biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `logits` is a matrix with `num_images` rows and `num_classes` columns, where the element of the $i$'th row and $j$'th column is an estimate of how likely the $i$'th input image is to be of the $j$'th class.\n",
    "\n",
    "However, these estimates are a bit rough and difficult to interpret because the numbers may be very small or large, so we want to normalize them so that each row of the `logits` matrix sums to one, and each element is limited between zero and one. This is calculated using the so-called softmax function and the result is stored in `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted class can be calculated from the `y_pred` matrix by taking the index of the largest element in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the model better at classifying the input images, we must somehow change the variables for `weights` and `biases`. To do this we first need to know how well the model currently performs by comparing the predicted output of the model `y_pred` to the desired output `y`.\n",
    "\n",
    "The softmax is a generalization of the logistic function, it is used to calculate the probability associated to each class and it is usefull in multiclass classification problems. A softmax regression has two steps: first we add up the evidence of our input being in certain classes, and then we convert that evidence into probabilities. Here a class is one of the 10 possibile digits. \n",
    "\n",
    "Next we define the cost function, cross entropy in this case. Cross-entropy gives us a way to express how different two probability distributions are. The more different the distributions p and q are, the more the cross-entropy of p with respect to q will be bigger than the entropy of p. Similarly, the more different p is from q, the more the cross-entropy of q with respect to p will be bigger than the entropy of q. If the distributions are the same, this difference will be zero. As the difference grows, it will get bigger.\n",
    "\n",
    "The goal of optimization is therefore to minimize the cross-entropy so it gets as close to zero as possible by changing the `weights` and `biases` of the model.\n",
    "\n",
    "TensorFlow has a built-in function for calculating the cross-entropy. Note that it uses the values of the `logits` because it also calculates the softmax internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                        labels=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now calculated the cross-entropy for each of the image classifications so we have a measure of how well the model performs on each image individually. But in order to use the cross-entropy to guide the optimization of the model's variables we need a single scalar value, so we simply take the average of the cross-entropy for all the image classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a cost measure that must be minimized, we can then create an optimizer. In this case it is the basic form of Gradient Descent where the learning rate is set at $0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a few more performance measures to display the progress to the user.\n",
    "\n",
    "This is a vector of booleans whether the predicted class equals the true class of each image. \n",
    "\n",
    "This calculates the classification accuracy by first type-casting the vector of booleans to floats, so that False becomes 0 and True becomes 1, and then calculating the average of these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(logits), 1), \n",
    "                              tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 50.000 images in the training-set. It takes a long time to calculate the gradient of the model using all these images. We therefore use Stochastic Gradient Descent which only uses a small batch of images in each iteration of the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_ITERATIONS = 1000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for performing a number of optimization iterations so as to gradually improve the `weights` and `biases` of the model. In each iteration, a new batch of data is selected from the training-set and then TensorFlow executes the optimizer using those training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(NUM_ITERATIONS):\n",
    "    x_batch, y_batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "\n",
    "    feed_dict_train = {x: x_batch,\n",
    "                       y: y_batch}\n",
    "\n",
    "    session.run(optimizer, feed_dict=feed_dict_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dict test contains test data that the model has not seen during the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feed_dict_test = {x: mnist.test.images,\n",
    "                  y: mnist.test.labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = session.run(accuracy, feed_dict=feed_dict_test)\n",
    "    \n",
    "print(\"Accuracy on test set: {0:.1%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cls_true = np.argmax(mnist.test.labels, axis=1)\n",
    "\n",
    "cls_pred = session.run(y_pred_cls, feed_dict=feed_dict_test)\n",
    "\n",
    "cm = confusion_matrix(y_true=cls_true,\n",
    "                      y_pred=cls_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "Visit [www.add-for.com](<http://www.add-for.com/IT>) for more tutorials and updates.\n",
    "\n",
    "This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
